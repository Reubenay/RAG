{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e88511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    print(\"⚠️ Warning: OPENAI_API_KEY not found. Set it in .env file.\")\n",
    "else:\n",
    "    print(\"✅ API key loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f565693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# Load PDF\n",
    "loader = PyPDFLoader(\"About_Reuben.pdf\")\n",
    "documents = loader.load()   # returns List[Document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cb9c2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 2 documents into 8 chunks\n",
      "\n",
      "Chunk 1: About Me - Reuben Mulero\n",
      "I  am  Reuben  Mulero,  a  graduate  in  Entrepreneurship  (Entrepreneurial  Studies) from  the  Federal\n",
      "University of Agriculture, Abeokuta (FUNAAB), and a passionate full-stack AI developer. My journey has\n",
      "been defined by a relentless curiosity, a strong problem-solving mindset, and a dedication to creating real-\n",
      "world solutions through technology and innovation.\n",
      "From the beginning, I have always been drawn to understanding systems and building solutions that have\n",
      "tangible impact. My academic and professional experiences have equipped me with a unique combination\n",
      "\n",
      "Chunk 2: of technical skills, leadership abilities, and business insight.\n",
      "Technical Expertise and Projects\n",
      "I specialize in full-stack development, building both the frontend and backend of web applications with a\n",
      "strong focus on usability, scalability, and performance. My technical toolkit includes: - Frontend: React, Vite,\n",
      "Tailwind CSS - Backend: FastAPI - Database: MySQL - AI Integration: Gemini API, LLM-based chat systems\n",
      "I have created several notable projects that demonstrate my capability to deliver complete systems:\n",
      "\n",
      "Chunk 3: E-commerce Web Platform: Built with React, Tailwind, FastAPI, and MySQL. The platform features\n",
      "seamless product management, user authentication, and dynamic interaction between frontend and\n",
      "backend, providing a full shopping experience.\n",
      "Business-Oriented AI Chat Systems: Developed chatbots that respond strictly to business-related\n",
      "queries. I implemented custom AI prompts, structured outputs, and frontend integration to ensure\n",
      "accurate and professional responses.\n",
      "Portfolio and Personal Projects: Developed various web applications showcasing my skills in React,\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=60,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "# Split documents\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Split {len(documents)} documents into {len(chunks)} chunks\")\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"\\nChunk {i+1}: {chunk.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "763ee7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Reuben Mulero is a builder by instinct and a problem-solver by choice.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 448, 'total_tokens': 465, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CmfNwFk23ub0CEbMjrG49nwv8gmO7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b1cce-84f4-7892-9d00-86470e628035-0' usage_metadata={'input_tokens': 448, 'output_tokens': 17, 'total_tokens': 465, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.docstore.document import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "# Convert documents\n",
    "lc_docs = chunks\n",
    "\n",
    "# Vector store (Chroma)\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=openai_api_key\n",
    ")\n",
    "\n",
    "\n",
    "# persist_directory allows saving DB locally; optional\n",
    "vectorstore = Chroma.from_documents(\n",
    "    lc_docs,\n",
    "    embeddings,\n",
    "    collection_name=\"my_rag_collection\",\n",
    "    persist_directory=\"./chroma_db\"  # optional\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4}\n",
    ")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    openai_api_key=openai_api_key\n",
    ")\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are an expert assistant. Answer ONLY using the provided context. \"\n",
    "     \"If the answer is not in the context, say it is not available.\"\n",
    "    ),\n",
    "    (\"human\",\n",
    "     \"Question: {question}\\n\\nContext:\\n{context}\"\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "# Build RAG pipeline\n",
    "rag_chain = (\n",
    "    RunnableParallel(context=retriever, question=RunnablePassthrough())\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# Query\n",
    "response = rag_chain.invoke(\"tell me about Reuben mulero?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "716330c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conversational RAG chain ready\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Store histories\n",
    "chat_store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in chat_store:\n",
    "        chat_store[session_id] = InMemoryChatMessageHistory()\n",
    "    return chat_store[session_id]\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Prompt\n",
    "conv_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are an expert assistant. Answer ONLY using the provided context. \"\n",
    "     \"If the answer is not in the context, say you do not know.\"\n",
    "    ),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"Context:\\n{context}\\n\\nQuestion: {question}\")\n",
    "])\n",
    "\n",
    "# Base chain\n",
    "conv_chain_base = (\n",
    "    RunnableParallel(\n",
    "        context=lambda x: format_docs(retriever.invoke(x[\"question\"])),\n",
    "        question=lambda x: x[\"question\"],\n",
    "        chat_history=lambda x: []  # REQUIRED placeholder\n",
    "    )\n",
    "    | conv_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# History wrapper\n",
    "conv_chain = RunnableWithMessageHistory(\n",
    "    conv_chain_base,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "print(\"✅ Conversational RAG chain ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "690b6031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuben Mulero is a builder by instinct and a problem-solver by choice.\n"
     ]
    }
   ],
   "source": [
    "response = conv_chain.invoke(\n",
    "    {\"question\": \"Who is Reuben Mulero?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user-1\"}}\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7606a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He designs impactful systems and leads innovative projects.\n"
     ]
    }
   ],
   "source": [
    "response = conv_chain.invoke(\n",
    "    {\"question\": \"What does he do?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user-1\"}}\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfea4da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "His skills include technical expertise in full-stack development, with a focus on frontend and backend web application development using tools like React, Vite, Tailwind CSS, FastAPI, MySQL, and AI integration with Gemini API and LLM-based chat systems. Additionally, he has leadership abilities and business insight, as demonstrated by his role as the Public Relations Officer for FUNIEC, where he honed skills in messaging, stakeholder engagement, and project promotion.\n"
     ]
    }
   ],
   "source": [
    "response = conv_chain.invoke(\n",
    "    {\"question\": \"What are his skills?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user-1\"}}\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
