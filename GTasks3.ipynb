{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bc098a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import Literal\n",
    "\n",
    "# Load environment variables (API Key)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dfba47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Found 3 PDFs. Loading...\n",
      "   - Loaded: 2010-the-venture-capital-revolution.pdf\n",
      "   - Loaded: Entrepreneurship_Development_in_Nigeria.pdf\n",
      "   - Loaded: ssrn-4350545.pdf\n",
      "‚úÖ Total loaded pages: 247\n",
      "‚úÖ Created 695 chunks\n"
     ]
    }
   ],
   "source": [
    "# Path to your PDF directory\n",
    "folder_path = \"data/business_docs\"\n",
    "\n",
    "# 1. Load PDF Documents\n",
    "documents = []\n",
    "pdf_files = glob.glob(os.path.join(folder_path, \"*.pdf\"))\n",
    "\n",
    "if not pdf_files:\n",
    "    raise FileNotFoundError(f\"No PDF files found in {folder_path}\")\n",
    "\n",
    "print(f\"üìÇ Found {len(pdf_files)} PDFs. Loading...\")\n",
    "\n",
    "for file_path in pdf_files:\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    # Using standard load() for simplicity, comparable to the notebook's async approach\n",
    "    docs = loader.load()\n",
    "    documents.extend(docs)\n",
    "    print(f\"   - Loaded: {os.path.basename(file_path)}\")\n",
    "\n",
    "print(f\"‚úÖ Total loaded pages: {len(documents)}\")\n",
    "\n",
    "# 2. Split into Chunks (Module 2 knowledge applied in Section 3)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # Characters per chunk\n",
    "    chunk_overlap=100     # Overlap to preserve context\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(documents)\n",
    "print(f\"‚úÖ Created {len(doc_splits)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943c8878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vector store created and persisted to ./chroma_db_business\n"
     ]
    }
   ],
   "source": [
    "# 3. Create Vector Store\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Define persistence path (optional, but good practice as shown in notebook)\n",
    "chroma_path = \"./chroma_db_business\"\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"business_knowledge\",\n",
    "    persist_directory=chroma_path\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Vector store created and persisted to {chroma_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ea0a62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieval tool created\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def retrieve_business_knowledge(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information in the business document knowledge base.\n",
    "    \n",
    "    Use this tool when the user asks about specific business concepts, \n",
    "    strategies, or details contained in the provided PDFs.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query describing the information needed.\n",
    "        \n",
    "    Returns:\n",
    "        Relevant document excerpts to answer the question.\n",
    "    \"\"\"\n",
    "    # Use MMR (Maximum Marginal Relevance) for diversity, as in the notebook\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\": 5, \"fetch_k\": 10}\n",
    "    )\n",
    "    \n",
    "    results = retriever.invoke(query)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant business documents found.\"\n",
    "    \n",
    "    # Format results with citations\n",
    "    formatted = \"\\n\\n---\\n\\n\".join(\n",
    "        f\"Source: {doc.metadata.get('source', 'Unknown')}, Page {doc.metadata.get('page', 0)}\\n{doc.page_content}\"\n",
    "        for doc in results\n",
    "    )\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "print(\"‚úÖ Retrieval tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1f4488b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agentic RAG System Compiled\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Bind tools\n",
    "tools = [retrieve_business_knowledge]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# System Prompt (Customized for Business Domain)\n",
    "system_prompt = SystemMessage(content=\"\"\"You are an expert Business Consultant Agent with access to a knowledge base.\n",
    "\n",
    "RETRIEVAL DECISION RULES:\n",
    "- DO NOT retrieve for greetings or general knowledge (\"What is 2+2?\").\n",
    "- DO retrieve for specific questions about business strategies, financial metrics, or content found in the uploaded documents.\n",
    "- Always cite the source when providing information from the documents.\n",
    "\"\"\")\n",
    "\n",
    "# Define Assistant Node\n",
    "def assistant(state: MessagesState) -> dict:\n",
    "    messages = [system_prompt] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Define Conditional Logic\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "\n",
    "# Build Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", should_continue, {\"tools\": \"tools\", \"__end__\": END})\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# Compile with Memory\n",
    "memory = MemorySaver()\n",
    "agent = builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"‚úÖ Agentic RAG System Compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f14e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üë§ User: What are the key topics discussed in these documents?\n",
      "==================================================\n",
      "üîç Agent: [Decided to retrieve information]\n",
      "ü§ñ Response: The key topics discussed in the documents include:\n",
      "\n",
      "1. **Globalization**: The documents explore the implications of globalization on business, referencing significant works by Martin Wolf and Jagdish Bhagwati that analyze the subject comprehensively.\n",
      "\n",
      "2. **Environmental Challenges**: There is a focus on current and prospective environmental problems, emphasizing the need for a global partnership for sustainable development as outlined in Agenda 21, which addresses disparities, poverty, and ecosystem deterioration.\n",
      "\n",
      "3. **Capitalism and Collectivism**: The documents discuss the interplay between capitalism and collectivism, highlighting the role of various coalitions, including government and UN agencies, in promoting sustainable development and corporate social responsibility.\n",
      "\n",
      "4. **Human Rights**: The concept of 'positive' human rights is presented as a critical element in the discourse surrounding business practices and societal expectations.\n",
      "\n",
      "These topics reflect a broader discussion on the role of business in addressing global challenges and the evolving expectations of corporate responsibility.\n",
      "\n",
      "==================================================\n",
      "üë§ User: Hello, are you ready to help?\n",
      "==================================================\n",
      "üß† Agent: [Decided to answer directly]\n",
      "ü§ñ Response: I'm here to assist you with any business-related questions or strategies you may have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "def run_query(user_input: str, thread_id: str):\n",
    "    print(f\"\\n{'='*50}\\nüë§ User: {user_input}\\n{'='*50}\")\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    result = agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=user_input)]},\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    # Analysis of the result\n",
    "    messages = result[\"messages\"]\n",
    "    tool_calls = [msg for msg in messages if isinstance(msg, AIMessage) and msg.tool_calls]\n",
    "    \n",
    "    if tool_calls:\n",
    "        print(f\"üîç Agent: [Decided to retrieve information]\")\n",
    "    else:\n",
    "        print(f\"üß† Agent: [Decided to answer directly]\")\n",
    "        \n",
    "    print(f\"ü§ñ Response: {messages[-1].content}\")\n",
    "\n",
    "# Run Tests\n",
    "run_query(\"What are the key topics discussed in these documents?\", \"test_1\")\n",
    "run_query(\"Hello, are you ready to help?\", \"test_2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
